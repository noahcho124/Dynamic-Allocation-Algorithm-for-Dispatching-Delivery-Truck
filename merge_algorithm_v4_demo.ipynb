{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.simplefilter(\n",
    "    action='ignore', category=FutureWarning)  # FutureWarning 제거\n",
    "from time import time\n",
    "from sklearn.cluster import DBSCAN\n",
    "from alpha_shapes import Alpha_Shaper, plot_alpha_shape\n",
    "\n",
    "\n",
    "# # Define Util Function \n",
    "\n",
    "def vol_merge(truck_df):\n",
    "    '''\n",
    "    트럭의 물량을 합포장하는 함수\n",
    "    '''\n",
    "    unique_cds = truck_df['SPG_INNB'].unique()\n",
    "    SPG_INNB_lst = []\n",
    "    x_lst = []\n",
    "    y_lst = []\n",
    "    reassign_lst = []\n",
    "    _assign_lst = []\n",
    "    KRRI_REC_S_lst = []\n",
    "    dong_lst = []\n",
    "    deliver_lst = []\n",
    "    volume_lst = []\n",
    "    iter_lst = []\n",
    "    \n",
    "    for idx, code in tqdm(enumerate(unique_cds)):\n",
    "        SPG_INNB_lst.append(truck_df[truck_df['SPG_INNB'] == code]['SPG_INNB'].values[0])\n",
    "        x_lst.append(truck_df[truck_df['SPG_INNB'] == code]['x'].values[0])\n",
    "        y_lst.append(truck_df[truck_df['SPG_INNB'] == code]['y'].values[0])\n",
    "        reassign_lst.append(truck_df[truck_df['SPG_INNB'] == code]['reassign'].values[0])\n",
    "        _assign_lst.append(truck_df[truck_df['SPG_INNB'] == code]['assign'].values[0])\n",
    "        KRRI_REC_S_lst.append(truck_df[truck_df['SPG_INNB'] == code]['KRRI_REC_S'].values[0])\n",
    "        dong_lst.append(truck_df[truck_df['SPG_INNB'] == code]['dong'].values[0])\n",
    "        deliver_lst.append(truck_df[truck_df['SPG_INNB'] == code]['deliver'].values[0])\n",
    "        iter_lst.append(truck_df[truck_df['SPG_INNB'] == code]['iter'].values[0])\n",
    "\n",
    "        volume_sum = truck_df[truck_df['SPG_INNB'] == code]['volume'].sum()\n",
    "        volume_lst.append(volume_sum)\n",
    "\n",
    "        # print('-------{}th row work ahs been complete-------'.format(idx))\n",
    "\n",
    "    res = pd.DataFrame({'SPG_INNB':SPG_INNB_lst,\\\n",
    "                        'x': x_lst, 'y': y_lst, 'reassign': reassign_lst, '_assign': _assign_lst, \\\n",
    "                        'KRRI_REG_CD': KRRI_REC_S_lst, 'dong': dong_lst, 'deliver': deliver_lst, 'volume': volume_lst, 'iter': iter_lst})\n",
    "    # res.columns = [, , , , , 'KRRI_REG_CD', 'dong', 'deliver', 'volume', 'iter']\n",
    "\n",
    "    return res\n",
    "\n",
    "def distance(x1, y1, x2, y2):\n",
    "    '''\n",
    "    두 점 사이의 거리를 구하는 함수\n",
    "    '''\n",
    "    result = math.sqrt(math.pow(x1 - x2, 2) + math.pow(y1 - y2, 2))\n",
    "    return result\n",
    "\n",
    "def closest_membership(cl: int, new_merber_matrix):\n",
    "    '''\n",
    "    특정 클러스터로부터 멤버쉽밸류가 가장 큰 노드를 구하는 함수\n",
    "    '''\n",
    "    res = new_merber_matrix[new_merber_matrix[cl] == new_merber_matrix[cl].max()]\n",
    "    return res\n",
    "\n",
    "def closest_point(cl: int, new_dist_matrix):\n",
    "    '''\n",
    "    특정 클러스터를 대상으로 가장 가까운 거리의 점을 구하는 함수\n",
    "    '''\n",
    "    res = new_dist_matrix[new_dist_matrix[str(cl)] == new_dist_matrix[str(cl)].min()]\n",
    "    return res\n",
    "\n",
    "def furthest_point(cl: int, new_dist_matrix) -> pd.DataFrame:\n",
    "    '''\n",
    "    특정 클러스터를 대상으로 가장 먼 거리의 점을 구하는 함수\n",
    "    '''\n",
    "    res = new_dist_matrix[new_dist_matrix[str(cl)] == new_dist_matrix[str(cl)].max()]\n",
    "    return res\n",
    "\n",
    "def update_distance_matrix(mt_df, center_df) -> pd.DataFrame:\n",
    "    '''\n",
    "    현재 물량의 데이터와 가중 평균중심 좌표로 각 클러스터와 모든 노드 간의 거리를 업데이트 하는 함수\n",
    "    '''\n",
    "    dist_matrix = pd.DataFrame(index=range(0,len(mt_df)), columns = ['0','1','2','3','4','5','6','7','8','9'])\n",
    "    for i in range(len(mt_df)):\n",
    "        for j in range(len(center_df)):\n",
    "            result = distance(mt_df.loc[i]['x'], mt_df.loc[i]['y'],center_df.loc[j]['x'],center_df.loc[j]['y'])\n",
    "            dist_matrix.loc[i][j] = result\n",
    "            #print(mt_df.loc[i]['x'], mt_df.loc[i]['y']) \n",
    "\n",
    "    for i in range(10):\n",
    "        mt_df['{0}'.format(i)]  = pd.to_numeric(dist_matrix['{0}'.format(i)])\n",
    "    \n",
    "    return mt_df\n",
    "\n",
    "def update_weighted_center_df(mt_df):\n",
    "    '''\n",
    "    현재 물량을 기준으로 클러스터 별 가중 평균 중심점을 업데이트하는 함수\n",
    "    '''\n",
    "    weighted_avg_x_lst = []\n",
    "    weighted_avg_y_lst = []\n",
    "    for i in range(10):\n",
    "        temp_df = mt_df[mt_df['reassign'] == i]\n",
    "        weighted_avg_x = (temp_df['x'] * temp_df['volume'] * temp_df['update_weight']).sum() / (temp_df['volume']* temp_df['update_weight']).sum()\n",
    "        weighted_avg_y = (temp_df['y'] * temp_df['volume'] * temp_df['update_weight']).sum() / (temp_df['volume']* temp_df['update_weight']).sum()\n",
    "\n",
    "        weighted_avg_x_lst.append(weighted_avg_x)\n",
    "        weighted_avg_y_lst.append(weighted_avg_y)\n",
    "\n",
    "    weighted_center = {'x': weighted_avg_x_lst,\n",
    "                'y': weighted_avg_y_lst}\n",
    "    weighted_center_df = pd.DataFrame(weighted_center)\n",
    "\n",
    "    return weighted_center_df\n",
    "\n",
    "def update_volume_lst(mt_df):\n",
    "    '''\n",
    "    각 클러스터별 물량을 업데이트하는 함수\n",
    "    '''\n",
    "    vol_lst = [0] * 10\n",
    "    for cl_n in range(10):\n",
    "        temp_df = mt_df[mt_df['reassign'] == cl_n]\n",
    "        vol_lst[cl_n] = temp_df['volume'].sum()\n",
    "    print(vol_lst)\n",
    "        \n",
    "    return vol_lst\n",
    "\n",
    "def MAE(x,y):\n",
    "    '''\n",
    "    클러스터의 노드 교환이 끝난 시점에서 MAE를 구하는 함수\n",
    "    '''\n",
    "    x = np.array(x)\n",
    "    y = np.array([y]*len(x))\n",
    "    res = np.abs(np.subtract(x,y)).mean()\n",
    "    \n",
    "    return res\n",
    "\n",
    "def min_2(lst):\n",
    "    sorted_lst = sorted(lst)\n",
    "    result = sorted_lst[1]\n",
    "    return result\n",
    "\n",
    "vol_dict = {}\n",
    "\n",
    "for day in range(20,21):\n",
    "    main_truck = pd.read_csv('./Information/opArea_pop_outputSegok.csv', index_col=0)\n",
    "    df = pd.read_csv(\"./Input/main_truck_{:02d}.csv\".format(day), index_col=0) ## 송장데이터를 넣는 곳 매번 바뀔 수 있음\n",
    "    # 원래 02\n",
    "    main_truck[\"volume\"] = 0\n",
    "    main_truck.drop(columns='idx', inplace=True)\n",
    "    #각 행별로 SPG_INNB값을 셀거에요 \n",
    "    #main_truck의 SPG_INNB와 Input data의 SPG_INNB가 같다면! main_truck의 volume 값을 1씩 더해줄 거에요~\n",
    "    for index, row in df.iterrows():\n",
    "        spg = row['SPG_INNB']\n",
    "        volume = row['volume']\n",
    "        main_truck.loc[main_truck['SPG_INNB'] == spg, 'volume'] += volume #df.loc[row, column], 2400개의 물량을 510개의 cell 중 어디에 해당하는지 넣는듯\n",
    "    filter_cond = main_truck[\"volume\"]!=0\n",
    "    main_truck = main_truck[filter_cond]\n",
    "    main_truck.reset_index(inplace=True)\n",
    "    main_truck['index'] = range(len(main_truck))\n",
    "    # 당일 물량 없는 cell은 지우고 나머지에 대해서만 다루는듯 \n",
    "    ## master data\n",
    "    ## master data rarely changes\n",
    "    org_cens = pd.read_csv('./Information/output_cluster_centroids.csv', header=None) # 기존 클러스터 센트로이드 정보 -> 10개 \n",
    "    mv = pd.read_csv('./Information/output_membership_value.csv', header=None) # 전체 노드의 멤버쉽 밸류 -> 510 개 \n",
    "    op_segok = pd.read_csv('./Information/opArea_pop_outputSegok.csv', index_col=0) # 전체 노드의 아이디, 좌표, reassign 정보를 담고 있음\n",
    "    #main_truck: 간선차량\n",
    "    #df: Input(송장번호)\n",
    "    org_cens.columns = ['x', 'y'] # df에 column 이름을 붙여준 것\n",
    "    mv_df = pd.concat([op_segok['SPG_INNB'], mv], axis=1) # cell 고유번호와 cell의 merbership value를 옆으로 이어붙임 \n",
    "\n",
    "    main_truck['reassign'] = 10\n",
    "    new_mem_matrix = pd.merge(main_truck[['SPG_INNB', 'x', 'y', 'volume']], mv_df, how='inner') # 공통 column(SPG_INNB)를 기준으로 병합\n",
    "    # [SPG_INNB, x, y, volume, merbership value]\n",
    "\n",
    "    volume_lst = [0] * 10\n",
    "    new_mem_matrix_co = copy(new_mem_matrix)\n",
    "    ## 균형을 맞추면서 가까운 노드 먹어가기 -> seed decision\n",
    "    while min(volume_lst) <= len(df) / 10  * 0.75: # 고정의 비율을 조정하는 라인 # df : node, 10 : cluster # 적어도 하나의 클러스터가 균등물량의 75%는 처리해야함  \n",
    "        target_cl = volume_lst.index(min(volume_lst)) # min 값을 가진 index\n",
    "        temp_rec = closest_membership(target_cl, new_mem_matrix_co) # 남은 cell 중 target_cl에 대해 가장 높은 membership value를 가진 행 in new_mem_martrix_co\n",
    "        key = main_truck['SPG_INNB'][temp_rec.index[0]] # 위의 cell의 index \n",
    "        volume_lst[target_cl] += temp_rec['volume'].values[0] # target_cl에 temp_rec의 volume을 추가 \n",
    "        main_truck.loc[main_truck['SPG_INNB'] == key, 'reassign'] = target_cl # 위의 cell의 클러스터 번호를 기존에서 target_cl로 변경 \n",
    "        new_mem_matrix_co.drop([temp_rec.index[0]], inplace=True) # 이번에 사용한 cell을 제거  \n",
    "        # 이거는 volume_lst 합이 2400이 안돼도 괜찮은가? \n",
    "        # 위의 while 조건 대로면 new_mem_matrix_co에 cell이 남을텐데 \n",
    "\n",
    "    print(volume_lst)\n",
    "\n",
    "    ## 균형 안맞추면서 가까운 노드 먹어가기 (추가)\n",
    "    for _, i in enumerate(range(len(new_mem_matrix_co))):\n",
    "        designate_cl = new_mem_matrix_co.iloc[i][[i for i in range(10)]].argmax()\n",
    "        # print(new_mem_matrix_co.iloc[i])\n",
    "        key = main_truck['SPG_INNB'][new_mem_matrix_co.index[i]]\n",
    "        # print(key)\n",
    "        volume_lst[designate_cl] += int(new_mem_matrix_co.iloc[i]['volume'])\n",
    "        main_truck.loc[main_truck['SPG_INNB'] == key, 'reassign'] = designate_cl\n",
    "    print(volume_lst)\n",
    "\n",
    "    org_cens = pd.read_csv('./Information/output_cluster_centroids.csv', header=None) # 기존 클러스터 센트로이드 정보\n",
    "    org_cens.columns = ['x', 'y']  \n",
    "    print(main_truck['SPG_INNB'].duplicated().sum()) # 중복되는 집계구 없이 join되었는지 확인\n",
    "    print(main_truck['volume'].sum()) # 총 물량 합 확인\n",
    "    main_truck['update_weight'] = 1\n",
    "    main_truck['hindrance'] = 0 # 방해 \n",
    "    weighted_center_df = update_weighted_center_df(main_truck) # 가중평균 센트로이드 초기화\n",
    "    # 위에서 클러스터당 최소 75%의 물량을 처리하도록 reassign 하고나면 \n",
    "    main_truck_co = main_truck.copy(deep=True)\n",
    "    org_cens_dist = update_distance_matrix(main_truck_co, org_cens)#main_truck.copy() # 3번째 elif문에서 쓸 org_cens와 노드간 거리 데이터\n",
    "    main_truck = update_distance_matrix(main_truck, weighted_center_df)\n",
    "    \n",
    "    main_truck.reset_index(inplace=True)\n",
    "    \n",
    "    vol_lst = update_volume_lst(main_truck)\n",
    "    ## update_weight를 변화시키기 위한 파라미터 설정\n",
    "    u_param = 1.9\n",
    "    limit_volume = 240\n",
    "    ## 클러스터 물량의 표준편차 & MAE를 저장하기 위한 리스트\n",
    "    std_lst = []\n",
    "    mae_lst=[]\n",
    "    truck_capa = 260\n",
    "    case_off = 0\n",
    "    ## 클러스터별 볼륨값 초기화\n",
    "    vol_lst = update_volume_lst(main_truck)\n",
    "    print('initial volume is', vol_lst)\n",
    "    iteration = 0\n",
    "    ## 클러스터 볼륨이 260 미만이 될 때까지 작동함\n",
    "    while max(vol_lst) > truck_capa:\n",
    "        ## 각 클러스터에 대해서 순차적으로 균등화 작업 수행\n",
    "        for i in range(10):\n",
    "            ## 균등화 작업을 수행하는 클러스터 지정\n",
    "            init_cluster = i\n",
    "            print('\\n--------------------Current init cluster {}--------------------\\n'.format(init_cluster))\n",
    "            ## 균등화 작업을 하는 양을 미리 지정 260과의 차이를 절대값으로 계산\n",
    "            target_volume = abs(main_truck[main_truck['reassign'] == init_cluster]['volume'].sum() - 240)\n",
    "            ## 점진적 작업을 위해서 작업 물량의 240과의 차이의 절반으로 정의\n",
    "            target_volume /= 2\n",
    "            target_volume = math.ceil(target_volume) # 자릿수 올림\n",
    "\n",
    "            cumulative_volume = 0 # 현재 작업량 초기화\n",
    "            main_truck_prev = main_truck.copy(deep=True)\n",
    "            alpha_lst_prev = []\n",
    "            for z in range(10):\n",
    "                a = main_truck[main_truck['reassign'] == z]\n",
    "                points = a[['x','y']].values\n",
    "                shaper = Alpha_Shaper(points)\n",
    "                # Calculate the shape\n",
    "                alpha = 0.5\n",
    "                alpha_shape = shaper.get_shape(alpha=alpha)\n",
    "                area = round(alpha_shape.area*1000000,6)\n",
    "                alpha_lst_prev.append(area)\n",
    "            ## 만약 작업하려는 클러스터가 물량이 over 되는 상황이라면 여기 분기로 들어옴\n",
    "            ## 이 분기에서는 over되는 물량을 다른 클러스터에 나눠주게 됨\n",
    "            if vol_lst[i] > limit_volume:\n",
    "                cand = main_truck[main_truck['reassign'] == i] \n",
    "                for j in range(len(cand)):\n",
    "                    moving_p_cand = main_truck[(main_truck['reassign'] == i) & (main_truck['ecoVehicle'] != 1)]\n",
    "                    p1 = moving_p_cand[str(i)].idxmax()\n",
    "                    d1_ser = moving_p_cand.loc[p1] # i번째 클러스터에서 가장 멀리있는 점(row)을 뽑음 --> 시리즈 형식\n",
    "                    if d1_ser[[str(i) for i in range(10)]].values.argmin() == i: # i번째 클러스터가 가장 가까운 경우 2번째로 가까운데로 보내줘야 함\n",
    "                        temp_lst = d1_ser[[str(i) for i in range(10)]].values\n",
    "                        cl1 = np.argpartition(d1_ser[[str(i) for i in range(10)]].values, 1)\n",
    "                        cl1 = cl1[1]\n",
    "                        d1 = min_2(temp_lst)\n",
    "                        print('case1-1')\n",
    "                        \n",
    "                    else:\n",
    "                        cl1 = d1_ser[[str(i) for i in range(10)]].values.argmin()\n",
    "                        d1 = d1_ser[[str(i) for i in range(10)]].values.min() # 그게 아니면 그냥 제일 가까운 클러스터(현재 속한 클러스터 X)로 보내줌\n",
    "                        print('case1-2')\n",
    "                                \n",
    "                    d2_cand = moving_p_cand[[str(k) for k in range(10)]].min() # 가장 가까운 거리 \n",
    "                    p2_cand = moving_p_cand[[str(k) for k in range(10)]].idxmin() # 내가 아닌 가장 가까운 클러스터 거리를 가진 cell \n",
    "                    dp2 = pd.concat([d2_cand,p2_cand], axis=1)\n",
    "                    dp2_sorted = dp2.sort_values(by=0, ascending=True) # '0'열(d2) 기준으로 오름차순 정렬\n",
    "                    if int(dp2_sorted.index[0]) == i: \n",
    "                        d2 = min_2(d2_cand)\n",
    "                        p2 = int(dp2_sorted.iloc[1,1])\n",
    "                        cl2 = int(dp2_sorted.index[1])\n",
    "                        print('case2-1')\n",
    "                    else: \n",
    "                        d2 = d2_cand.min()\n",
    "                        p2 = int(dp2_sorted.iloc[0,1])\n",
    "                        cl2 = int(dp2_sorted.index[0])\n",
    "                        print('case2-2')\n",
    "                        \n",
    "                    if d1 > d2 and main_truck.iloc[p2,main_truck.columns.get_loc('hindrance')] < 5:\n",
    "                        print(\"\\nCurrent Moving Point's ID: {}\".format(main_truck.iloc[p2, main_truck.columns.get_loc('SPG_INNB')]))\n",
    "                        print('바뀐 클러스터는',cl2, '기존 클러스터는', main_truck.iloc[p2, main_truck.columns.get_loc('reassign')])\n",
    "                        print(\"\\nHindrance: {}\".format(main_truck.iloc[p2, main_truck.columns.get_loc('hindrance')]))\n",
    "                        main_truck.iloc[p2, main_truck.columns.get_loc('reassign')] = cl2\n",
    "                        main_truck.iloc[p2, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                        main_truck.iloc[p2, main_truck.columns.get_loc('hindrance')] += 1\n",
    "                        cumulative_volume += main_truck.iloc[p2,main_truck.columns.get_loc('volume')]\n",
    "                        vol_lst = update_volume_lst(main_truck)\n",
    "                        \n",
    "                        print('넘친경우, if')\n",
    "                    elif d1 < d2 and main_truck.iloc[p1,main_truck.columns.get_loc('hindrance')] == 5: # org_cens를 기준으로 옮겨준다면?\n",
    "                        print(\"\\nCurrent Moving Point's ID: {}\".format(main_truck.iloc[p1, main_truck.columns.get_loc('SPG_INNB')]))\n",
    "                        print('바뀐 클러스터는',cl1, '기존 클러스터는', main_truck.iloc[p1, main_truck.columns.get_loc('reassign')])\n",
    "                        print(\"\\nHindrance: {}\".format(main_truck.iloc[p1, main_truck.columns.get_loc('hindrance')]))\n",
    "                        main_truck.iloc[p1, main_truck.columns.get_loc('reassign')] = cl1\n",
    "                        main_truck.iloc[p1, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                        cumulative_volume += d1_ser['volume']\n",
    "                        vol_lst = update_volume_lst(main_truck)\n",
    "                        \n",
    "                        print('넘친경우, elif')\n",
    "                        #elif문을 추가해서 d1이 주가 되긴 하나, 클러스터 간 교차점이 생길거 같으면 d2를 옮기게 조건문 수정\n",
    "                    else:\n",
    "                        cl1_cand = org_cens_dist.iloc[p1,:]\n",
    "                        if cl1_cand[[str(i) for i in range(10)]].values.argmin() == init_cluster:\n",
    "                            indice = np.argpartition(cl1_cand[[str(i) for i in range(10)]].values,1)\n",
    "                            cl1 = indice[1]\n",
    "                            print('case4-1')\n",
    "                        else:\n",
    "                            cl1 = cl1_cand[[str(i) for i in range(10)]].values.argmin()\n",
    "                            print('case4-2')\n",
    "                        main_truck.iloc[p1, main_truck.columns.get_loc('reassign')] = cl1\n",
    "                        # main_truck.iloc[p1, main_truck.columns.get_loc('hindrance')] += 1 # 이 경우에는 hindrance 안더하는게 맞다\n",
    "                        # main_truck.iloc[p1, main_truck.columns.get_loc('update_weight')] *= u_param #이 경우에는 가중치 곱하지 말까?\n",
    "                        print(\"\\nCurrent Moving Point's ID: {}\".format(main_truck.iloc[p1, main_truck.columns.get_loc('SPG_INNB')]))\n",
    "                        print(\"\\nHindrance: {}\".format(main_truck.iloc[p1, main_truck.columns.get_loc('hindrance')]))\n",
    "                        cumulative_volume += cl1_cand['volume']\n",
    "                        vol_lst = update_volume_lst(main_truck)                       \n",
    "                        \n",
    "                        print('넘친경우, else')\n",
    "          \n",
    "                    print('Target Volume: {0}\\t Current Cummulative Volume: {1}'.format(target_volume, cumulative_volume))\n",
    "                    if cumulative_volume >= target_volume:\n",
    "                        weighted_center_df = update_weighted_center_df(main_truck)\n",
    "                        main_truck = update_distance_matrix(main_truck, weighted_center_df)\n",
    "                        std_lst.append(np.std(vol_lst))\n",
    "                        mae_lst.append(MAE(vol_lst,limit_volume))\n",
    "                        # for i in range(10):\n",
    "                        #     a = main_truck[main_truck['reassign'] == i]\n",
    "                        #     plt.scatter(a['x'], a['y'])\n",
    "                        # plt.scatter(weighted_center_df['x'],weighted_center_df['y'], c= 'blue', marker= \"D\")\n",
    "                        # plt.scatter(org_cens['x'], org_cens['y'], c='k', marker=\"D\")\n",
    "                        # for i in range(10):\n",
    "                        #     plt.annotate(str(i), (org_cens['x'][i], org_cens['y'][i]), (org_cens['x'][i]+0.0001, org_cens['y'][i]+0.0001), c='k')\n",
    "                        #     plt.annotate(str(i), (weighted_center_df['x'][i], weighted_center_df['y'][i]), (weighted_center_df['x'][i]+0.0001, weighted_center_df['y'][i]+0.0001), c='blue')\n",
    "                        # # plt.show()\n",
    "                        # plt.savefig('0315_img/Day_20_pic/{0:02d}_{1:02d}'.format(iteration,init_cluster))\n",
    "                        # plt.close()\n",
    "                        print('init_cluster{} has been done'.format(init_cluster))\n",
    "                        break\n",
    "                if max(vol_lst) <= 260:\n",
    "                    break\n",
    "            ## 이 분기에서는 short되는 물량을 다른 클러스터에서 가져오게 됨\n",
    "            elif vol_lst[i] < limit_volume:\n",
    "                ## 현재 작업이 수행 중인 클러스터에 속하지 않는 포인트들을\n",
    "                ## 가장 가까이 있는 점부터 정렬하여\n",
    "                ## 이동시킬 포인트들의 후보를 저장\n",
    "                moving_p_cand = main_truck[(main_truck['reassign'] != i) & (main_truck['ecoVehicle'] != 1)].sort_values(by=[str(i)], ascending=True)\n",
    "                for j in range(len(moving_p_cand)):\n",
    "                    moving_p = moving_p_cand.iloc[j]\n",
    "                    print(\"\\nCurrent Moving Point's ID: {}\".format(moving_p['SPG_INNB']))\n",
    "                    print(\"Current Moving Point's cluster: {}\".format(moving_p['reassign'])) # 추가적으로 이동 포인트의 기존 클러스터 정보를 출력\n",
    "                    print(\"Current Moving Point's Volume: {}\".format(moving_p['volume']))\n",
    "                    temp_idx = moving_p['index']\n",
    "                    # main_truck.iloc[temp_idx, main_truck.columns.get_loc('reassign')] = init_cluster # 현재 이동포인트를 작업 중인 클러스터로 편입\n",
    "                    # main_truck.iloc[temp_idx, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                    # 이동 포인트에서 가장 거리가 가까운 클러스터가 현재 작업 중인 클러스터가 맞을 경우\n",
    "                    if moving_p[[str(i) for i in range(10)]].values.argmin() == init_cluster:\n",
    "                        main_truck.iloc[temp_idx, main_truck.columns.get_loc('reassign')] = init_cluster # 현재 이동포인트를 작업 중인 클러스터로 편입\n",
    "                        main_truck.iloc[temp_idx, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                    ## 이동 포인트에서 가장 거리가 가까운 클러스터가 현재 작업 중인 클러스터가 맞을 경우(보통의 경우, 원래 해당하는 클러스터에 가까움)\n",
    "                    else:\n",
    "                        ## 2번째로 가까운 클러스터에 편입시킴 -> 이럴 경우 작업 중인 클러스터가 잡힘\n",
    "                        indice = np.argpartition(moving_p[[str(i) for i in range(10)]].values,1)\n",
    "                        target_cluster = indice[1]\n",
    "                        if target_cluster == init_cluster:\n",
    "                            main_truck.iloc[temp_idx, main_truck.columns.get_loc('reassign')] = target_cluster\n",
    "                            main_truck.iloc[temp_idx, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                        # if cumulative_volume + moving_p['volume'] > target_volume:\n",
    "                        # else: \n",
    "                        #     continue\n",
    "                            \n",
    "                        elif target_cluster != init_cluster:\n",
    "                            print('!!!!!!taget and init is different!!!!!!')\n",
    "                            # main_truck.iloc[temp_idx, main_truck.columns.get_loc('reassign')] = target_cluster\n",
    "                            # main_truck.iloc[temp_idx, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                            continue\n",
    "\n",
    "                    cumulative_volume += moving_p['volume']\n",
    "                    print('Target Volume: {0}\\t Current Cummulative Volume: {1}'.format(target_volume, cumulative_volume))\n",
    "                    vol_lst = update_volume_lst(main_truck)\n",
    "            \n",
    "\n",
    "                    if cumulative_volume >= target_volume:\n",
    "                        weighted_center_df = update_weighted_center_df(main_truck)\n",
    "                        main_truck = update_distance_matrix(main_truck, weighted_center_df)\n",
    "                        std_lst.append(np.std(vol_lst))\n",
    "                        mae_lst.append(MAE(vol_lst,limit_volume))\n",
    "                        # for i in range(10):\n",
    "                        #     a = main_truck[main_truck['reassign'] == i]\n",
    "                        #     plt.scatter(a['x'], a['y'])\n",
    "                        # plt.scatter(weighted_center_df['x'],weighted_center_df['y'], c= 'blue', marker= \"D\")\n",
    "                        # plt.scatter(org_cens['x'], org_cens['y'], c='k', marker=\"D\")\n",
    "                        # for i in range(10):\n",
    "                        #     plt.annotate(str(i), (org_cens['x'][i], org_cens['y'][i]), (org_cens['x'][i]+0.0001, org_cens['y'][i]+0.0001), c='k')\n",
    "                        #     plt.annotate(str(i), (weighted_center_df['x'][i], weighted_center_df['y'][i]), (weighted_center_df['x'][i]+0.0001, weighted_center_df['y'][i]+0.0001), c='blue')\n",
    "                        # # plt.show()\n",
    "                        # plt.savefig('0315_img/Day_20_pic/{0:02d}_{1:02d}'.format(iteration,init_cluster))\n",
    "                        # plt.close()\n",
    "                        print('init_cluster{} has been done'.format(init_cluster))\n",
    "                        break\n",
    "                if max(vol_lst) <= truck_capa:\n",
    "                    break\n",
    "            alpha_lst_fw = []\n",
    "            for z in range(10):\n",
    "                a = main_truck[main_truck['reassign'] == z]\n",
    "                points = a[['x','y']].values\n",
    "                shaper = Alpha_Shaper(points)\n",
    "                # Calculate the shape\n",
    "                alpha = 0.5\n",
    "                alpha_shape = shaper.get_shape(alpha=alpha)\n",
    "                area = round(alpha_shape.area*1000000,6)\n",
    "                alpha_lst_fw.append(area)\n",
    "            for z in range(10):\n",
    "                prev = alpha_lst_prev[z]\n",
    "                fw = alpha_lst_fw[z]\n",
    "                res = fw / prev\n",
    "                if res > 1.6:\n",
    "                    print('Roll Back')\n",
    "                    case_off += 1\n",
    "                    main_truck = main_truck_prev.copy(deep=True)\n",
    "                    vol_lst = update_volume_lst(main_truck)\n",
    "                    if vol_lst[z] > limit_volume:\n",
    "                        target_volume = vol_lst[z] - limit_volume\n",
    "                    else:\n",
    "                        target_volume = math.ceil(vol_lst[z]*(20/100))\n",
    "                    '''d1조건으로 넘겨줄 거에용'''\n",
    "                    cand = main_truck[main_truck['reassign'] == z] \n",
    "                    for j in range(len(cand)):\n",
    "                        moving_p_cand = main_truck[(main_truck['reassign'] == z) & (main_truck['ecoVehicle'] != 1)]\n",
    "                        p1 = moving_p_cand[str(z)].idxmax()\n",
    "                        d1_ser = moving_p_cand.loc[p1] # i번째 클러스터에서 가장 멀리있는 점(row)을 뽑음 --> 시리즈 형식\n",
    "                        if d1_ser[[str(z) for z in range(10)]].values.argmin() == z: # i번째 클러스터가 가장 가까운 경우 2번째로 가까운데로 보내줘야 함\n",
    "                            temp_lst = d1_ser[[str(z) for z in range(10)]].values\n",
    "                            cl1 = np.argpartition(d1_ser[[str(z) for z in range(10)]].values, 1)\n",
    "                            cl1 = cl1[1]\n",
    "                            d1 = min_2(temp_lst)\n",
    "                            print('case1-1')\n",
    "                            \n",
    "                        else:\n",
    "                            cl1 = d1_ser[[str(z) for z in range(10)]].values.argmin()\n",
    "                            d1 = d1_ser[[str(z) for z in range(10)]].values.min() # 그게 아니면 그냥 제일 가까운 클러스터(현재 속한 클러스터 X)로 보내줌\n",
    "                            print('case1-2')\n",
    "                        print(\"\\nCurrent Moving Point's ID: {}\".format(main_truck.iloc[p1, main_truck.columns.get_loc('SPG_INNB')]))\n",
    "                        print('바뀐 클러스터는',cl1, '기존 클러스터는', main_truck.iloc[p1, main_truck.columns.get_loc('reassign')])\n",
    "                        print(\"\\nHindrance: {}\".format(main_truck.iloc[p1, main_truck.columns.get_loc('hindrance')]))\n",
    "                        main_truck.iloc[p1, main_truck.columns.get_loc('reassign')] = cl1\n",
    "                        main_truck.iloc[p1, main_truck.columns.get_loc('update_weight')] *= u_param\n",
    "                        cumulative_volume += d1_ser['volume']\n",
    "                        vol_lst = update_volume_lst(main_truck)\n",
    "                        \n",
    "                        if cumulative_volume >= target_volume:\n",
    "                            weighted_center_df = update_weighted_center_df(main_truck)\n",
    "                            main_truck = update_distance_matrix(main_truck, weighted_center_df)\n",
    "                            print('Roll back ended')\n",
    "                            break\n",
    "        iteration += 1\n",
    "        print('This iteration :', iteration)\n",
    "        if iteration == 100:\n",
    "            break\n",
    "    # vol_dict['day_{:02d}'.format(day)] = case_lst\n",
    "    print('LEVELING FINISHED')\n",
    "    print(iteration)\n",
    "    vol_lst = update_volume_lst(main_truck)\n",
    "    vol_dict[\"Before_DBSCAN_Day_{:02d}\".format(day)] = vol_lst\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    # main_truck = main_truck\n",
    "    predicted_df = pd.DataFrame()\n",
    "    # del main_truck['outlier']\n",
    "    for i in range(10):\n",
    "        # print(i)\n",
    "        smpl_df = main_truck[main_truck['reassign'] == i]\n",
    "        data = smpl_df[['x', 'y']]\n",
    "\n",
    "        mdl = DBSCAN(0.0015, min_samples=4)\n",
    "        predict = pd.DataFrame(mdl.fit_predict(data))\n",
    "        predict.columns=['outlier']\n",
    "        \n",
    "        smpl_df.reset_index(drop=True, inplace=True)\n",
    "        smpl_df = pd.concat([smpl_df, predict['outlier']], axis=1)\n",
    "        # smpl_df['outlier'] = predict['outlier']\n",
    "        smpl_df['outlier'] = smpl_df['outlier'].apply(lambda x : 1 if x == -1 else 0)\n",
    "        # plt.scatter(smpl_df['x'], smpl_df['y'], c=smpl_df['outlier'])\n",
    "        # plt.title('{} Cluster DBSCAN Result'.format(i))\n",
    "        # plt.show()\n",
    "        predicted_df = pd.concat([predicted_df, smpl_df], axis=0)\n",
    "\n",
    "    main_truck = pd.merge(main_truck, predicted_df[['SPG_INNB', 'outlier']], how='left', on='SPG_INNB')\n",
    "    outliers_df = main_truck[main_truck['outlier'] == 1]\n",
    "    for i in range(len(outliers_df)):\n",
    "        outlier_p = outliers_df.iloc[i]\n",
    "        temp_idx = outlier_p['index']\n",
    "        print(outlier_p[[str(i) for i in range(10)]].values.argmin())\n",
    "        if outlier_p['reassign'] != outlier_p[[str(j) for j in range(10)]].values.argmin():\n",
    "            main_truck.iloc[temp_idx, main_truck.columns.get_loc('reassign')] = outlier_p[[str(i) for i in range(10)]].values.argmin()\n",
    "        \n",
    "        # plt.scatter(smpl_df['x'], smpl_df['y'], c=smpl_df['outlier'])\n",
    "        # plt.show()\n",
    "        \n",
    "        # outliers = smpl_df[smpl_df['predict'] == -1]\n",
    "    vol_lst = update_volume_lst(main_truck)\n",
    "    print(vol_lst)\n",
    "    vol_dict[\"After_DBSCAN_Day_{:02d}\".format(day)] = vol_lst\n",
    "    # main_truck.to_csv('0304_img/Day_{:02d}.csv'.format(day))\n",
    "    ## 전체 시각화\n",
    "    for i in range(10):\n",
    "        a = main_truck[main_truck['reassign'] == i]\n",
    "        plt.scatter(a['x'], a['y'])\n",
    "    plt.scatter(weighted_center_df['x'],weighted_center_df['y'], c= 'blue', marker= \"D\")\n",
    "    plt.scatter(org_cens['x'], org_cens['y'], c='k', marker=\"D\")\n",
    "    for i in range(10):\n",
    "        plt.annotate(str(i), (org_cens['x'][i], org_cens['y'][i]), (org_cens['x'][i]+0.0001, org_cens['y'][i]+0.0001), c='k')\n",
    "        plt.annotate(str(i), (weighted_center_df['x'][i], weighted_center_df['y'][i]), (weighted_center_df['x'][i]+0.0001, weighted_center_df['y'][i]+0.0001), c='blue')\n",
    "    plt.show()\n",
    "    # plt.savefig('0315_img/Day_20_pic/Day_{:02d}_최종'.format(day))\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "위의 리스트 day의 main_truck 다 불러와.\n",
    "node의 ID & reassign값을 기반 value_count진행.\n",
    "normalize 진행\n",
    "x,y,reassign, normalize값을 토대로 시각화 진행 (interactive library such as bokeh, plotly)\n",
    "'''\n",
    "combined_df = pd.read_csv('./Information/opArea_pop_outputSegok.csv', index_col=0)\n",
    "combined_df = combined_df[['SPG_INNB', 'x', 'y', 'reassign']]\n",
    "combined_df[['probability','0','1','2','3','4','5','6','7','8','9']] = 0\n",
    "combined_df.index = combined_df['SPG_INNB']\n",
    "for day in [3,4,6,9,10,12,16,17,21,22,24,26,28,29,30]:\n",
    "    main_truck = pd.read_csv('0304_img/Day_{:02d}.csv'.format(day))\n",
    "    for idx, row in main_truck.iterrows():\n",
    "        spg_innb = row['SPG_INNB']\n",
    "        reassign_value = row['reassign']\n",
    "        combined_df.loc[spg_innb, str(reassign_value)] += 1\n",
    "combined_df['total'] = combined_df.iloc[:, 5:15].sum(axis=1)\n",
    "# def find_max_index(row):\n",
    "#     return row[[str(i) for i in range(10)]].argmax()\n",
    "# combined_df['reassign'] = combined_df.apply(find_max_index, axis=1)\n",
    "# combined_df.index = range(len(combined_df))\n",
    "# for i in range(len(combined_df)):\n",
    "#     row = combined_df.iloc[i]\n",
    "#     cl = int(row['reassign']) \n",
    "#     probability = row[str(cl)] / (row['total'] + 0.0001)\n",
    "#     combined_df.loc[i, 'probability'] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "for i in range(10):\n",
    "    fig = px.scatter(combined_df, x='x', y='y', opacity=combined_df['{0}'.format(i)] / (combined_df['total'] + 0.0001),\n",
    "                    text= round(combined_df['{0}'.format(i)] / (combined_df['total'] + 0.0001), 5), title = 'cluster_{}'.format(i))\n",
    "\n",
    "    # 각각의 scatter plot을 추가합니다.\n",
    "    # for i in range(1, 10):\n",
    "    #     fig.add_traces(px.scatter(combined_df, x='x', y='y', opacity=combined_df['{0}'.format(i)] / (combined_df['total'] + 0.0001),\n",
    "    #                                color_discrete_sequence=[px.colors.qualitative.Plotly[i]]))\n",
    "    hover_text = ['x: {}<br>y: {}<br>probability: {:.5f}<br>SPG_INNB: {}'.format(x, y, p, SPG_INNB) for x, y, p, SPG_INNB in zip(combined_df['x'], combined_df['y'], combined_df['{0}'.format(i)] / (combined_df['total'] + 0.0001), combined_df['SPG_INNB'])]\n",
    "    fig.update_traces(mode='markers', hovertemplate=hover_text)\n",
    "\n",
    "\n",
    "    # fig.update_traces(mode='markers',\n",
    "    #                   hovertemplate='x: %{x}<br>' +\n",
    "    #                   'y: %{y}<br>'+\n",
    "    #                   'probability: %{text}<br>')\n",
    "    # fig.show()\n",
    "    # 그래프 출력\n",
    "    fig.write_html('0304_img/plotly_{0}_revised.html'.format(i))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
